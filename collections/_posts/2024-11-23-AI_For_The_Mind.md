---
#
#   Copyright 2024 Martín E. Zahnd
#
#   Licensed under the Apache License, Version 2.0 (the "License");
#   you may not use this file except in compliance with the License.
#   You may obtain a copy of the License at
#
#       https://www.apache.org/licenses/LICENSE-2.0
#
#   Unless required by applicable law or agreed to in writing, software
#   distributed under the License is distributed on an "AS IS" BASIS,
#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#   See the License for the specific language governing permissions and
#   limitations under the License.

# layout: note
layout: post

title: AI For The Mind
author: Martín E. Zahnd

# Force custom Date (in UTC)
# Example: 2021-10-22 05:02:23 -0300
date: 2024-11-23 23:47:10 -0300
# If it was edited, put the date here
# edit:

# Space separated tags
tags: ai itba essay

# Set to add KaTeX support in the html
equations: false

# Table Of Contents
toc: true
---

If I give you a knife, you'd probably try to cut some food, store it, or even give it back to me. You may also hurt me or yourself with it, on purpose or not.

<!--more-->

## AI, adults and... children?

Giving children cell phones and indiscriminate internet access is already showing signs of damage at both an individual and society level [^screen-time-1] [^screen-time-2].
Even giving "adults" unlimited access to internet and "fast answers" has been causing harm.

[^screen-time-1]:
    See [Associations Between Screen-Based Media Use and Brain White Matter Integrity in Preschool-Aged Children](https://jamanetwork.com/journals/jamapediatrics/fullarticle/2754101)

[^screen-time-2]:
    See [Screen time might be physically changing kids’ brains](https://www.technologyreview.com/2019/11/04/132071/screen-time-might-be-physically-changing-kids-brains/)

Those who really understand what "AI" is and what it can (and cannot) do, and those who have at least taken the time to investigate the tip of this iceberg, know that machines do not think. Even if LLMs answer our questions, translate more decently than classic translation software, and speak full sentences out loud, they are not _thinking_.

<iframe width="622" height="350" src="https://www.youtube.com/embed/gLrraUzG24w" title="The Ability To Speak Does Not Make You Intelligent [1080p]" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

But an industry that is "90% marketing and 10% reality"[^torvalds-ai] with almost $300 billion invested in it, which may be seen as "unlimited money"[^vc-ai], AI is now being injected in the non-technically educated minds of the people with the added conviction that they are capable of limited _thinking_.[^oh-no].

[^torvalds-ai]: See ["Linus Torvalds on AI"](https://x.com/tsarnick/status/1848182122609283439)

[^vc-ai]: See [Wealth, shown to scale](https://mkorostoff.github.io/1-pixel-wealth/) for a proper visualization. This scale uses the wealth of Jeff Bezos, Amazon's founder and CEO, at USD 185 billion. VCs have invested almost twice that much in AI companies.

[^oh-no]: Oh no! If they can do this now they'll steal our jobs in the future!

These same people who will let their children spend hours on their phones in order to "keep them quiet for a while", until roles switch and adolescents hide behind their phones to "keep them \[parents\] quiet for a while". Only to discover _stuff_ that leads them straight to their own death [^teen-suicide-1] [^teen-suicide-2].

[^teen-suicide-1]: 
    See [Hospitalization for Suicide Ideation or Attempt: 2008–2015](https://publications.aap.org/pediatrics/article-abstract/141/6/e20172426/37690/Hospitalization-for-Suicide-Ideation-or-Attempt?redirectedFrom=fulltext)] 

[^teen-suicide-2]: 
    See [Trends in Suicide Among Youth Aged 10 to 19 Years in the United States, 1975 to 2016](https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2733430)

That was caused by social media! An LLM will never _ever_ tell a user to do such a thing, [wouldn't it?](https://www.tomshardware.com/tech-industry/artificial-intelligence/gemini-ai-tells-the-user-to-die-the-answer-appears-out-of-nowhere-as-the-user-was-asking-geminis-help-with-his-homework): they are trained by the biggest companies in the world, they should be rightly and ethically trained to allow progress of humanity as a whole and not [that of a single nation or as a tool for spying over its users](https://openai.com/index/openai-appoints-retired-us-army-general/) [^nakasone].

[^nakasone]: General Paul M. Nakasone was the NSA leader during the previous Trump administration. The "famous" agency that has been denounced to spy on its own citizens.

## The Educated Fools

Nothing could go wrong, Skynet doesn't exists, and the most intelligent and educated people on earth, scientists, do not trust it blindly and certainly would never use for their papers.

Except [scientists do use it](https://www.theregister.com/2024/05/03/ai_scientific_articles/), and some people have even started experimenting with [war drones with "AI"](https://youtu.be/g_1XNdWEAGU) .
If this seems too far away or too pessimistic, remember that Ukraine [started using drones as early as the beginning of the Russo-Ukrainian War in 2014](https://www.popularmechanics.com/flight/drones/a25281/ukraine-makeshift-drones/) and in the past ten years has develop _drone war_ to be extremely cost-effective and precise [^drone-videos]. This is very little time for a war that has only became full-scale in the last two years.

[^drone-videos]: 
    If you search in the right subredits you will find war footage of civilian drones being used as bomb-drones in the span of those ten years, and how have they evolved.

War in between, we may have [Slaughterbots](https://youtu.be/9fa9lVwHHqg) here. Even with those who have devoted their lives to science and AI [warning us against this](https://youtu.be/9fa9lVwHHqg?t=432).

## Then what?

Should we make AI illegal? Prohibit it _somehow_?
Should we make phones illegal so children cannot access LLMs through them and their brains don't get damaged by them? Drones?

I don't think so. Prohibition of most things has always lead to unlawed usage of it, which ends up diminishing its quality, creating even more unethical businesses around that thing, and damaging society as a whole.

Children will do fine, eventually. Generation Z (1997-2010) and Generation Alpha (2010 to 2024) are the first generations to be born _with_ internet and _with_ smartphones already in the public hands and massively distributed. They are the children of the previous two generations, who have grown up only to discover the world changing completely in less than half their lives.
We are just starting to learn how to educate our children about the dangers and limitations of this new technology, while also educating ourselves the same.
Eventually, we'll learn enough about it and, who knows, maybe we recover from current [short attention spans in children](https://www.researchgate.net/publication/383410660_The_Effect_of_Excessive_Smartphone_Use_on_Child_Cognitive_Development_and_Academic_Achievement_A_Mixed_Method_Analysis_Corresponding_Author).

In matters of defense, it may become a race to a Nash equilibrium in which AI usage in war is like nuclear usage nowadays: all humanity is doomed is we use it that way. Or we may get to a state in which its just another decision making tool but never actually _takes_ the decision by itself and soldiers get trained to be extremely careful with trusting it.

## Hope

On the other hand AI, in all its shapes, may become the peacemaker of the world. We may see it transform the world in a place where wars do not exist, global warming isn't a problem anymore, and humanity, as a whole, advances peacefully.
I may be remembering The Evitable Conflict by Isaac Asimov a little bit too much, but I'm also inspired by the recent [Denmark's first AI supercomputer](https://blogs.nvidia.com/blog/denmark-sovereign-ai-supercomputer/) that will be used for science advancements [^fredrik-huang].

[^fredrik-huang]: Maybe Fredrik X and Jensen Huang are as fans of Asimov as I am. One can only dream.

But I have also been following advancements from IBM Watson [in healthcare](https://www.ibm.com/industries/healthcare), and [Tesla autopilot and full self-driving](https://www.tesla.com/support/autopilot). Two fields that represent 850 thousand [^medical-humans] and 44 thousand lives[^transport-stats], respectively that could be saved entirely and around 2.6 million each year who could _not_ get injured every year **only** in the United States.
AI advancements in these fields may imply that those more than 3.5 million people will continue to live their lives as they used to do for some more time. They do not have to do it "perfectly", we humans do not do it ourselves! They just have to be better than us and evolve enough to become essential for treating patients or drive.

[^medical-humans]: 
    Taking into account deaths caused by medical error, [between 250 and 400 thousand](https://www.cnbc.com/2018/02/22/medical-errors-third-leading-cause-of-death-in-america.html), and those by cancer, around [600 thousand](https://www.cancer.org/research/cancer-facts-statistics/all-cancer-facts-figures/cancer-facts-figures-2022.html)

[^transport-stats]:
    See: [About Transportation Safety - Centers for Disease Control and Prevention](https://www.cdc.gov/transportation-safety/about/index.html)

None of us knows what will happen. We can try and write our theories, read the news, papers, philosophical books and articles, and yet, never get to really know what will happen. Until it happens. Then we will know it for sure.

In the meantime, we may strive to educate ourselves and those around us with the limitations, benefits and dangers AI and technology as a whole posses. Hoping to find the real world _positronic brain_ that Isaac Asimov describes in its stories and developing a few supercomputers with it to solve our major problems.

I may have to revise this completely in ten years from now. If an armed drone doesn't find me first.

